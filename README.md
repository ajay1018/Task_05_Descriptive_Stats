# Task 05 â€“ Using LLMs for Sports Data Analysis

## ğŸ“˜ Objective
This project tests how well a Large Language Model (LLM) can answer natural language questions based on structured sports data. The dataset used is the Syracuse Men's Basketball 2023â€“24 season statistics.

## ğŸ“Š Dataset
- **Name:** Syracuse Men's Basketball Stats 2023â€“24
- **Source:** Team statistics PDF (cleaned into `basketball_2023_clean.csv`)
- **Note:** Dataset is local and excluded from GitHub.

## âœ… Work Done (First Reporting Period)
- Cleaned dataset from PDF and structured it as CSV
- Created Python validation script to compute ground-truth answers
- Designed and stored natural language prompts for testing
- Asked LLM questions and saved responses
- Compared answers to actual stats and recorded evaluation results

## ğŸ” Initial Observations
- LLM answered factual questions correctly (scorer, rebounds, 3PT%)
- Performed reasonably on â€œall-aroundâ€ player analysis
- Struggled with subjective strategy questions (offense vs. defense)

## ğŸ“‚ Repo Structure
Task_05_Descriptive_Stats/
â”œâ”€â”€ data/ (local only)
â”œâ”€â”€ prompts/ (text prompts used for testing)
â”œâ”€â”€ results/ (llm_responses and evaluation.csv)
â”œâ”€â”€ scripts/ (validation Python script)
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

## â­ï¸ Next Steps
- Refine prompt engineering to improve complex answers
- Try multiple LLMs (ChatGPT, Claude) for comparison
- Expand metrics for evaluating subjective responses
